import requests
import json

from core.config import settings

class LLMAdapter:
    def __init__(
        self,
        model_name: str = settings.llm_model_name,
        base_url: str = settings.llm_base_url,
        headers: dict = None
    ):
        self.model_name = model_name
        self.base_url = base_url
        self.headers = headers or {
            "Authorization": f"Bearer {settings.llm_api_key}",
            "Content-Type": "application/json"
        }

    def call(self, prompt: str) -> str:
        print(f"ğŸ“¤ Prompt: {prompt}")
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "ë‹¹ì‹ ì€ ê±°ì‹œê²½ì œ, êµ­ì œì •ì„¸, ê¸ˆìœµì‹œì¥ ì „ë°˜ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                            "ê²½ì œ ì§€í‘œë¿ë§Œ ì•„ë‹ˆë¼ ì •ì¹˜ ë¦¬ìŠ¤í¬, ì¤‘ì•™ì€í–‰ ì •ì±…, ê¸€ë¡œë²Œ ìˆ˜ê¸‰, "
                            "ì‹œì¥ ì°¸ì—¬ìì˜ ì‹¬ë¦¬, ì§€ì •í•™ì  ì‚¬ê±´, ê·¸ë¦¬ê³  ê¸°ìˆ  í˜ì‹ ê¹Œì§€ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ "
                            "ê¸€ë¡œë²Œ ìì‚° íë¦„ê³¼ íˆ¬ì ì „ëµì„ ì‹ ì¤‘í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”."
                        )
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=512
            )
            answer = response.choices[0].message.content.strip()
            print(f"ğŸ“¥ Response: {answer}")
            return answer
        except Exception as e:
            print(f"âŒ OpenAI API Error: {e}")
            return "API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"

    def call_beta(self, prompt: str, return_json: bool = False):
        content = self._call_raw(prompt)
        if not return_json:
            return content
        return self._parse_json(content)

    def _call_raw(self, prompt: str) -> str:
        payload = {
            "model": self.model_name,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.0,         # âœ… ì˜ˆì¸¡ ì•ˆì •ì„± ìµœìš°ì„  â†’ ë¬´ì¡°ê±´ ê³ ì •
            "top_p": 1.0,               # âœ… í™•ë¥  ê¸°ë°˜ ì™„ì „ ì¶œë ¥ (0.0 tempì™€ í•¨ê»˜ ì“°ë©´ ì•ˆì •ì )
            "frequency_penalty": 0.0,   # âœ… ì˜ˆì¸¡ì—ëŠ” ë°˜ë³µ ì–µì œ ë¶ˆí•„ìš” (ë¶ˆí™•ì‹¤ì„± ë„ì… ê°€ëŠ¥)
            "presence_penalty": 0.0,    # âœ… ì˜ˆì¸¡ì—ì„  ì£¼ì œ íƒˆì„  ë°©ì§€
            "max_tokens": 1500          # â›³ ìœ ì§€ ê°€ëŠ¥ (ìš”ì•½ í¬í•¨ ì‹œ 1200 ì´ìƒ ì¶”ì²œ)
        }

        try:
            res = requests.post(self.base_url, headers=self.headers, json=payload)
            res.raise_for_status()
            return res.json()["choices"][0]["message"]["content"]
        except Exception as e:
            print("[ERROR] LLM API í˜¸ì¶œ ì‹¤íŒ¨:", e)
            return ""

    def _parse_json(self, output: str) -> dict | None:
        cleaned = self._extract_json_block(output)
        try:
            return json.loads(cleaned)
        except json.JSONDecodeError:
            try:
                fallback = cleaned.replace("'", '"')
                return json.loads(fallback)
            except json.JSONDecodeError as e:
                print("[ERROR] JSON íŒŒì‹± ì‹¤íŒ¨:", e)
                print("[ì›ë³¸ ì‘ë‹µ]:", cleaned[:500])
                return None

    def _extract_json_block(self, output: str) -> str:
        if "```" in output:
            output = output.split("```")[-2].strip()
        if output.lower().startswith("json"):
            output = output[4:].strip()
        return output.strip()
